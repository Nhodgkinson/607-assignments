---
title: "Week 11 607"
author: "Neil Hodgkinson"
date: "2022-11-06"
output: html_document
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)

library(tidytext)

```

## Code from https://www.tidytextmining.com/sentiment.html
The below code to line 155 is directly from the text book "Text Mining with R" by Julia Silge and David Robinson

```{r}
library(janeaustenr)
library(dplyr)
library(stringr)

tidy_books <- austen_books() %>%
  group_by(book) %>%
  mutate(
    linenumber = row_number(),
    chapter = cumsum(str_detect(text, 
                                regex("^chapter [\\divxlc]", 
                                      ignore_case = TRUE)))) %>%
  ungroup() %>%
  unnest_tokens(word, text)
```

##

```{r}
nrc_joy <- get_sentiments("nrc") %>% 
  filter(sentiment == "joy")

tidy_books %>%
  filter(book == "Emma") %>%
  inner_join(nrc_joy) %>%
  count(word, sort = TRUE)

```

```{r}
library(tidyr)

jane_austen_sentiment <- tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(book, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% 
  mutate(sentiment = positive - negative)
```

```{r}
library(ggplot2)

ggplot(jane_austen_sentiment, aes(index, sentiment, fill = book)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~book, ncol = 2, scales = "free_x")
```

```{r}
pride_prejudice <- tidy_books %>% 
  filter(book == "Pride & Prejudice")

pride_prejudice

```

```{r}
afinn <- pride_prejudice %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index = linenumber %/% 80) %>% 
  summarise(sentiment = sum(value)) %>% 
  mutate(method = "AFINN")

bing_and_nrc <- bind_rows(
  pride_prejudice %>% 
    inner_join(get_sentiments("bing")) %>%
    mutate(method = "Bing et al."),
  pride_prejudice %>% 
    inner_join(get_sentiments("nrc") %>% 
                 filter(sentiment %in% c("positive", 
                                         "negative"))
    ) %>%
    mutate(method = "NRC")) %>%
  count(method, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment,
              values_from = n,
              values_fill = 0) %>% 
  mutate(sentiment = positive - negative)
```

```{r}
bind_rows(afinn, 
          bing_and_nrc) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")
```

```{r}
get_sentiments("nrc") %>% 
  filter(sentiment %in% c("positive", "negative")) %>% 
  count(sentiment)
```
```{r}
get_sentiments("bing") %>% 
  count(sentiment)

```

```{r}
bing_word_counts <- tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

bing_word_counts

```

```{r}
bing_word_counts %>%
  group_by(sentiment) %>%
  slice_max(n, n = 10) %>% 
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "Contribution to sentiment",
       y = NULL)
```

```{r}
custom_stop_words <- bind_rows(tibble(word = c("miss"),  
                                      lexicon = c("custom")), 
                               stop_words)

custom_stop_words

```

```{r}
library(wordcloud)

tidy_books %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))
```

##Extended code

Let's apply the above to the book "Dracula" by Bram Stoker. The character of Dracula has influenced pop culture for nearly 2 centuries and is one of the most iconic horror villains of all time.

```{r}
library(gutenbergr)
```


```{r}
Dracula <- gutenberg_download(345) #Grabbing the book Dracula by it's listed e-book number
```
## Using the above code
Below I will use the above code to create the needed environments to get the results from the book

```{r}
tidy_Dracula <- Dracula %>%
  mutate(linenumber = row_number(), chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]", ignore_case = TRUE)))) %>%
  unnest_tokens(word, text)
```

```{r}

positive_negative <- get_sentiments("loughran") %>% 
  filter(sentiment == "positive" | sentiment =="negative")

bing_Dracula_sentiment <- tidy_Dracula %>%
  inner_join(get_sentiments("bing")) %>%
  count(index = linenumber %/% 80, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)
```
##Using Loughran sentiment

The Leoghran Lexicon is mainly used for financial documents, so why would we want to use it for a fiction novel? We wouldn't, but to show the importance of appropriate lexicon choice and to satisfy the assignment requirements we will be using it. 


```{r}
loughran_Dracula_sentiment <- tidy_Dracula %>%
  inner_join(positive_negative) %>%
  count(index = linenumber %/% 80, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)
```

```{r}
par(mfrow=c(1,2))

ggplot(loughran_Dracula_sentiment, aes(index, sentiment)) +
  geom_col(show.legend = FALSE) 
```

```{r}
ggplot(bing_Dracula_sentiment, aes(index, sentiment)) +
  geom_col(show.legend = FALSE) 
```

```{r}
get_sentiments("loughran") %>% 
     filter(sentiment %in% c("positive", "negative")) %>% 
  count(sentiment)
```

```{r}
get_sentiments("bing") %>% 
  count(sentiment)
```


## Conclusion of the Loughran Lexicon
The amount of words it was able to assign an attribute of negative and positive was much smaller than what the bing was able to do. This is to be expected as financial and legal documents don't use language in the same way as a fiction book would. A novel needs to illustrate a world to a reader while a legal document is a record of fact. So the above should demonstrate the importance of lexicon choice and when to apply it. 



